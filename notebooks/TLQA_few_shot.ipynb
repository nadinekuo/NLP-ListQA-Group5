{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot TLQA with FlanT5\n",
    "\n",
    "Below, we run generative models FlanT5-large and FlanT5-XL in a few-shot setting by selecting demonstration examples from training set of TLQA, which was derived from tempLLama.\n",
    "- `flan-t5-large`: 780M params, 1GB mem\n",
    "- `flan-t5-xl`: 3B params, 12 GB mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: sentence-transformers in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (4.37.2)\n",
      "Requirement already satisfied: tqdm in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: numpy in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (0.23.0)\n",
      "Requirement already satisfied: Pillow in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.1)\n",
      "Requirement already satisfied: sympy in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.4.28)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: langchain-core in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (0.1.52)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from langchain-core) (0.1.59)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from langchain-core) (1.9.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from langchain-core) (8.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (3.10.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (4.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core) (2024.2.2)\n",
      "Requirement already satisfied: bert-score in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from bert-score) (2.3.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from bert-score) (2.1.4)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from bert-score) (4.37.2)\n",
      "Requirement already satisfied: numpy in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from bert-score) (1.24.3)\n",
      "Requirement already satisfied: requests in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from bert-score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from bert-score) (4.65.0)\n",
      "Requirement already satisfied: matplotlib in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from bert-score) (3.8.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from bert-score) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: filelock in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (4.12.1)\n",
      "Requirement already satisfied: sympy in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (2024.4.28)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.4.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->bert-score) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->bert-score) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->bert-score) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers==4.37.2 optimum==1.12.0 --quiet\n",
    "# !pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/ --quiet\n",
    "# !pip install langchain==0.1.9 --quiet\n",
    "# # !pip install chromadb\n",
    "# !pip install sentence_transformers==2.4.0 --quiet\n",
    "# !pip install unstructured --quiet\n",
    "# !pip install pdf2image --quiet\n",
    "# !pip install pdfminer.six==20221105 --quiet\n",
    "# !pip install unstructured-inference --quiet\n",
    "# !pip install faiss-gpu==1.7.2 --quiet\n",
    "# !pip install pikepdf==8.13.0 --quiet\n",
    "# !pip install pypdf==4.0.2 --quiet\n",
    "# !pip install pillow_heif==0.15.0 --quiet\n",
    "\n",
    "!pip install transformers==4.37.2 optimum==1.12.0 --quiet\n",
    "!pip install sentence-transformers\n",
    "!pip install langchain-core\n",
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running FlanT5-Large and FlanT5-XL (zero-shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m T5Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/flan-t5-large\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mT5ForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoogle/flan-t5-large\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList all Michael Jackson albums between 2000 and 2009.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:2595\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2591\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2592\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2593\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2594\u001b[0m         )\n\u001b[0;32m-> 2595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\", torch_dtype=torch.float16)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\").to('cuda')\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\")\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\")\n",
    "\n",
    "input_text = \"List all Michael Jackson albums between 2000 and 2009.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "# input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3212 \n",
      "\n",
      "question: List all entities that owned Absolute Radio, also known as Virgin 1215, from 2010 to 2020.\n",
      "answers: ['The Times Group (2010, 2011, 2012, 2013)', 'Bauer Radio (2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020)']\n",
      "type: P127\n",
      "subject: Absolute Radio\n",
      "answer_ids: {'The Times Group': 'Q972645', 'Bauer Radio': 'Q4873460'}\n",
      "wikidata_ID: Q4590187\n",
      "verified: True\n",
      "subject_label: Absolute Radio\n",
      "aliases: ['Virgin 1215', 'Virgin Radio', 'Virgin 105.8']\n",
      "final_answers: ['The Times Group (2010, 2011, 2012, 2013)', 'Bauer Radio (2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020)']\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "train_set = utils.json_to_list(\"../data/train_TLQA.json\")\n",
    "test_set = utils.json_to_list(\"../data/test_TLQA.json\")\n",
    "print(len(train_set), '\\n')\n",
    "example = train_set[45]\n",
    "for key in example.keys():\n",
    "    print(f\"{key}: {example[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-Shot Example Generation using KNN Search\n",
    "\n",
    "To select few-shot examples, we select examples from the training set that are close to each test example by using KNN search in a continuous vector space using any embedding model from sentence-transformers.\n",
    "We reuse the KNN search from https://anonymous.4open.science/r/ICAT-47FC/code/2wikimultihopqa/get_chatgpt_skill_transfer_knn.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/_iterative.cpython-311-darwin.so, 0x0002): Library not loaded: @rpath/liblapack.3.dylib\n  Referenced from: <CB06B8E9-5573-3234-A309-5114AFCED6F5> /Users/nadinekuo/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/_iterative.cpython-311-darwin.so\n  Reason: tried: '/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/liblapack.3.dylib' (no such file), '/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/../../../../../../liblapack.3.dylib' (no such file), '/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/liblapack.3.dylib' (no such file), '/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/../../../../../../liblapack.3.dylib' (no such file), '/Users/nadinekuo/miniconda3/bin/../lib/liblapack.3.dylib' (no such file), '/Users/nadinekuo/miniconda3/bin/../lib/liblapack.3.dylib' (no such file), '/usr/local/lib/liblapack.3.dylib' (no such file), '/usr/lib/liblapack.3.dylib' (no such file, not in dyld cache)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mKnnSearch\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sentence_transformers/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.7.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset, ParallelSentencesDataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sentence_transformers/datasets/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDenoisingAutoEncoderDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParallelSentencesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentencesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sentence_transformers/datasets/ParallelSentencesDataset.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtempfile\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __MODEL_HUB_ORGANIZATION__\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     import_from_string,\n\u001b[1;32m     28\u001b[0m     batch_to_device,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     truncate_embeddings,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantize_embeddings\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sentence_transformers/evaluation/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSimilarityFunction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimilarityFunction\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mBinaryClassificationEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryClassificationEvaluator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEmbeddingSimilarityEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingSimilarityEvaluator\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mInformationRetrievalEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InformationRetrievalEvaluator\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sentence_transformers/evaluation/BinaryClassificationEvaluator.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m average_precision_score\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/__init__.py:83\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     80\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     86\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compress, islice\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/scipy/sparse/__init__.py:283\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_arrays\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    279\u001b[0m     csr_array, csc_array, lil_array, dok_array, coo_array, dia_array, bsr_array\n\u001b[1;32m    280\u001b[0m )\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csgraph\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    287\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[1;32m    288\u001b[0m     lil, sparsetools, sputils\n\u001b[1;32m    289\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/scipy/sparse/csgraph/__init__.py:185\u001b[0m\n\u001b[1;32m    157\u001b[0m __docformat__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestructuredtext en\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnected_components\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    160\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaplacian\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    161\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshortest_path\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsgraph_to_masked\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    183\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegativeCycleError\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_laplacian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m laplacian\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shortest_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    187\u001b[0m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson,\n\u001b[1;32m    188\u001b[0m     NegativeCycleError\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traversal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    191\u001b[0m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[1;32m    192\u001b[0m     depth_first_tree, connected_components\n\u001b[1;32m    193\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/scipy/sparse/csgraph/_laplacian.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m isspmatrix\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Graph laplacian\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlaplacian\u001b[39m(\n\u001b[1;32m     13\u001b[0m     csgraph,\n\u001b[1;32m     14\u001b[0m     normed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     symmetrized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/__init__.py:120\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m==================================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dsolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterative Solvers for Sparse Linear Systems\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#from info import __doc__\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterative\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mminres\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minres\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlgmres\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lgmres\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/iterative.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextwrap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dedent\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _iterative\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_system\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/_iterative.cpython-311-darwin.so, 0x0002): Library not loaded: @rpath/liblapack.3.dylib\n  Referenced from: <CB06B8E9-5573-3234-A309-5114AFCED6F5> /Users/nadinekuo/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/_iterative.cpython-311-darwin.so\n  Reason: tried: '/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/liblapack.3.dylib' (no such file), '/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/../../../../../../liblapack.3.dylib' (no such file), '/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/liblapack.3.dylib' (no such file), '/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/../../../../../../liblapack.3.dylib' (no such file), '/Users/nadinekuo/miniconda3/bin/../lib/liblapack.3.dylib' (no such file), '/Users/nadinekuo/miniconda3/bin/../lib/liblapack.3.dylib' (no such file), '/usr/local/lib/liblapack.3.dylib' (no such file), '/usr/lib/liblapack.3.dylib' (no such file, not in dyld cache)"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class KnnSearch:\n",
    "    def __init__(self, data=None, num_trees=None, emb_dim=None):\n",
    "        self.num_trees = num_trees\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "    def get_embeddings_for_data(self, data_ls):\n",
    "        # NOTE: any embedding model from sentence-transformers can be used\n",
    "        model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "        embeddings = model.encode(data_ls)\n",
    "        return embeddings\n",
    "\n",
    "    def get_top_n_neighbours(self, sentence, data_emb, transfer_data, k):\n",
    "        \"\"\"\n",
    "        Retrieves the top k most similar questions for \"sentence\" based on cosine similarity from given embeddings \"data_emb\".\n",
    "\n",
    "        Parameters:\n",
    "        sentence (str): The input sentence to find similar questions for.\n",
    "        data_emb (np.ndarray): The embeddings for the transfer questions.\n",
    "        transfer_data (list): The list of transfer questions corresponding to data_emb.\n",
    "        k (int): The number of top similar questions to retrieve.\n",
    "\n",
    "        Returns:\n",
    "        list: A list of the top k similar questions from transfer_data and all similar questions from str_qa.\n",
    "        \"\"\"\n",
    "        sent_emb = self.get_embeddings_for_data(sentence)\n",
    "        top_questions = []\n",
    "\n",
    "        text_sims = cosine_similarity(data_emb,[sent_emb]).tolist()\n",
    "        results_sims = zip(range(len(text_sims)), text_sims)\n",
    "        sorted_similarities = sorted(results_sims, key=lambda x: x[1], reverse=True)  # Obtain the highest similarities\n",
    "\n",
    "        # NOTE: we only match based on questions, but include the full question-answer pair in resulting neighs\n",
    "        for idx, item in sorted_similarities[:k]:\n",
    "                    top_questions.append(transfer_data[idx])\n",
    "\n",
    "        return top_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts all questions from the (train) set used for getting neighbours\n",
    "def get_transfer_questions(transfer_data):\n",
    "    transfer_questions = []\n",
    "    for index, data in enumerate(transfer_data):\n",
    "        transfer_questions.append(data[\"question\"])\n",
    "    return transfer_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::cumsum.out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Keep questions only to embed (to use in similarity metric)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m train_questions \u001b[38;5;241m=\u001b[39m get_transfer_questions(train_data)\n\u001b[0;32m----> 7\u001b[0m train_questions_emb \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embeddings_for_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_questions\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mKnnSearch.get_embeddings_for_data\u001b[0;34m(self, data_ls)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings_for_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_ls):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# NOTE: any embedding model from sentence-transformers can be used\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers/all-mpnet-base-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_ls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py:516\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    513\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 516\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    518\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py:117\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    115\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 117\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    120\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/mpnet/modeling_mpnet.py:550\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m extended_attention_mask: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extended_attention_mask(attention_mask, input_shape)\n\u001b[1;32m    549\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 550\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    552\u001b[0m     embedding_output,\n\u001b[1;32m    553\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    557\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    558\u001b[0m )\n\u001b[1;32m    559\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/mpnet/modeling_mpnet.py:93\u001b[0m, in \u001b[0;36mMPNetEmbeddings.forward\u001b[0;34m(self, input_ids, position_ids, inputs_embeds, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m         position_ids \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_position_ids_from_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m         position_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_position_ids_from_inputs_embeds(inputs_embeds)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/mpnet/modeling_mpnet.py:1054\u001b[0m, in \u001b[0;36mcreate_position_ids_from_input_ids\u001b[0;34m(input_ids, padding_idx)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# The series of casts and type-conversions here are carefully balanced to both work with ONNX export and XLA.\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m mask \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mne(padding_idx)\u001b[38;5;241m.\u001b[39mint()\n\u001b[0;32m-> 1054\u001b[0m incremental_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype_as(mask) \u001b[38;5;241m*\u001b[39m mask\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m incremental_indices\u001b[38;5;241m.\u001b[39mlong() \u001b[38;5;241m+\u001b[39m padding_idx\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::cumsum.out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "knn = KnnSearch()\n",
    "\n",
    "# Read raw dataset to a list containing question and answers (no metadata)\n",
    "train_data = utils.json_to_list(\"../data/train_TLQA.json\")\n",
    "# Keep questions only to embed (to use in similarity metric)\n",
    "train_questions = get_transfer_questions(train_data)\n",
    "train_questions_emb = knn.get_embeddings_for_data(train_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all positions Per Sandberg held from 2015 to 2018.\n",
      "['Minister of Fisheries (2015, 2016, 2017, 2018)', 'Minister of Justice and Public Security (2017, 2018)']\n",
      "\n",
      "\n",
      "List all positions Mark Drakeford held from 2013 to 2020.\n",
      "['Minister for Health and Social Services (2013, 2014, 2015, 2016)', 'First Minister of Wales (2018, 2019, 2020)']\n",
      "\n",
      "\n",
      "List all positions David M. O'Connell held from 2010 to 2020.\n",
      "['diocesan bishop (2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020)', 'Catholic bishop (2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020)']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: loop over test samples during/before inference time to create few-shot prompts\n",
    "# question = \"List all employers Elon Musk worked for from 1990 to 2024.\"\n",
    "question = \"List all positions held by Mark Zuckerberg from 2000 to 2024.\"\n",
    "neighs = knn.get_top_n_neighbours(sentence=question, data_emb=train_questions_emb, transfer_data=train_data, k=3)   # data_emb is embedded questions only, so we only match questions\n",
    "for neigh in neighs:\n",
    "    print(neigh['question'])\n",
    "    print(neigh['answers'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Few-Shot Prompt Template using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'List all positions Per Sandberg held from 2015 to 2018.', 'answers': ['Minister of Fisheries (2015, 2016, 2017, 2018)', 'Minister of Justice and Public Security (2017, 2018)']}, {'question': 'List all positions Mark Drakeford held from 2013 to 2020.', 'answers': ['Minister for Health and Social Services (2013, 2014, 2015, 2016)', 'First Minister of Wales (2018, 2019, 2020)']}, {'question': \"List all positions David M. O'Connell held from 2010 to 2020.\", 'answers': ['diocesan bishop (2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020)', 'Catholic bishop (2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020)']}]\n"
     ]
    }
   ],
   "source": [
    "def simplify_dict_list(dict_list):\n",
    "    return [{'question': item['question'], 'answers': item['answers']} for item in dict_list]\n",
    "\n",
    "simple_neighs = simplify_dict_list(neighs)\n",
    "print(simple_neighs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we configure a formatter that will format the few-shot examples into a string. This formatter should be a PromptTemplate object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: List all positions Mark Drakeford held from 2013 to 2020.\n",
      "['Minister for Health and Social Services (2013, 2014, 2015, 2016)', 'First Minister of Wales (2018, 2019, 2020)']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answers\"], template=\"Question: {question}\\n{answers}\"\n",
    ")\n",
    "\n",
    "print(example_prompt.format(**simple_neighs[1]))\n",
    "# print(example_prompt.format(question=f\"{simple_neighs[0]['question']}\", answers=f\"{simple_neighs[0]['answers']}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we feed examples and formatter to FewShotPromptTemplate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: List all positions Per Sandberg held from 2015 to 2018.\n",
      "['Minister of Fisheries (2015, 2016, 2017, 2018)', 'Minister of Justice and Public Security (2017, 2018)']\n",
      "\n",
      "Question: List all positions Mark Drakeford held from 2013 to 2020.\n",
      "['Minister for Health and Social Services (2013, 2014, 2015, 2016)', 'First Minister of Wales (2018, 2019, 2020)']\n",
      "\n",
      "Question: List all positions David M. O'Connell held from 2010 to 2020.\n",
      "['diocesan bishop (2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020)', 'Catholic bishop (2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020)']\n",
      "\n",
      "Question: List all positions held by Mark Zuckerberg between 2000 and 2020. Please answer this question in the same format as the three examples above.\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=simple_neighs,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "few_shot_prompt = prompt.format(input=\"List all positions held by Mark Zuckerberg between 2000 and 2020. Please answer this question in the same format as the three examples above.\")\n",
    "print(few_shot_prompt)   # String to feed to model during evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TLQA Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "# TODO: uncomment when using GPU\n",
    "# import accelerate\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\", torch_dtype=torch.float16)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")\n",
    "\n",
    "# Uncomment the line below to run on GPU\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\")\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1595.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "K = 10   # TODO: Experiment with 3, 5, 7, 10\n",
    "MAX_OUTPUT_LEN = 200\n",
    "MODEL_NAME = \"flan-t5-large\"  # TODO: Set accordingly\n",
    "\n",
    "results_GT_dict = {'prompts': [], 'outputs': [], 'output_tokens': [], \n",
    "                            'ground_truths': [], 'ground_truth_tokens': []}  \n",
    "\n",
    "# Configure formatter that will format the few-shot examples into a string\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answers\"], template=\"Question: {question}\\n{answers}\"\n",
    ")\n",
    "\n",
    "# Convert test set to list and loop over all items (1071 in total)\n",
    "for i, item in enumerate(test_set):\n",
    "    \n",
    "    # For each test question, retrieve k neighbours (try 3, 5, 7, 10)\n",
    "    test_question = test_set[i]['question']\n",
    "    neighs = knn.get_top_n_neighbours(sentence=test_question, data_emb=train_questions_emb, transfer_data=train_data, k=K)\n",
    "    simple_neighs = simplify_dict_list(neighs)\n",
    "\n",
    "    # Create the few-shot prompt template and feed to model\n",
    "    prompt = FewShotPromptTemplate(\n",
    "        examples=simple_neighs,\n",
    "        example_prompt=example_prompt,\n",
    "        suffix=\"Question: {input}\",\n",
    "        input_variables=[\"input\"],\n",
    "    )\n",
    "    few_shot_prompt = prompt.format(input=f\"{test_question} Please answer this question in the same format as the {K} examples above.\")\n",
    "    results_GT_dict['prompts'].append(few_shot_prompt)\n",
    "    \n",
    "    # TODO: pre-tokenize input and GT to speed up inference\n",
    "    input_ids = tokenizer(few_shot_prompt, return_tensors=\"pt\").input_ids\n",
    "    # TODO: ---------------------- UNCOMMENT WHEN USING GPU -----------------------------\n",
    "    # input_ids = tokenizer(few_shot_prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    output_tokens = model.generate(input_ids, max_length=MAX_OUTPUT_LEN)\n",
    "    output = tokenizer.decode(output_tokens[0])\n",
    "\n",
    "    results_GT_dict['output_tokens'].append(output_tokens[0])\n",
    "    results_GT_dict['outputs'].append(output)\n",
    "    results_GT_dict['ground_truths'].append(test_set[i]['final_answers'])\n",
    "    gt_tokens = tokenizer(str(test_set[i]['final_answers']), return_tensors=\"pt\").input_ids[0]\n",
    "    results_GT_dict['ground_truth_tokens'].append(gt_tokens)\n",
    "\n",
    "results_ds = Dataset.from_dict(results_GT_dict)\n",
    "results_ds.save_to_disk(f\"{K}_shot_{MODEL_NAME}.hf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the results Dataset from disk and inspect individual results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompts', 'outputs', 'output_tokens', 'ground_truths', 'ground_truth_tokens'],\n",
      "    num_rows: 5\n",
      "})\n",
      "\n",
      "MODEL OUTPUT:\n",
      "<pad> ['Teachta Dála (2010, 2012, 2013, 2014)', 'Labour Party (2010, 2011, 2012, 2013, 2014)', 'Labour Party (2010, 2011, 2012, 2013, 2014)', 'Labour Party (2010, 2011, 2012, 2013, 2014)']</s>\n",
      "\n",
      "OUTPUT TOKENS:\n",
      "[0, 784, 31, 382, 15, 9, 3997, 9, 309, 2975, 521, 41, 14926, 6, 1673, 6, 7218, 1412, 61, 31, 6, 3, 31, 18506, 1211, 3450, 41, 14926, 6, 8558, 1673, 6, 7218, 1412, 61, 31, 6, 3, 31, 18506, 1211, 3450, 41, 14926, 6, 8558, 1673, 6, 7218, 1412, 61, 31, 6, 3, 31, 18506, 1211, 3450, 41, 14926, 6, 8558, 1673, 6, 7218, 1412, 61, 31, 908, 1]\n",
      "\n",
      "GROUND TRUTH:\n",
      "['Socialist Party (2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019)', 'RISE (Ireland) (2019, 2020)']\n",
      "\n",
      "GT TOKENS:\n",
      "[784, 31, 5231, 4703, 343, 3450, 41, 14926, 6, 8558, 1673, 6, 7218, 1412, 6, 1230, 6, 5123, 4791, 4323, 1360, 61, 31, 6, 3, 31, 13431, 427, 41, 196, 60, 40, 232, 61, 41, 8584, 6, 6503, 61, 31, 908, 1]\n"
     ]
    }
   ],
   "source": [
    "results_ds = Dataset.load_from_disk(\"../results/10_shot_flan-t5-large_test.hf\")\n",
    "print(results_ds)\n",
    "idx_to_inspect = 2\n",
    "\n",
    "prompt = results_ds['prompts'][idx_to_inspect]\n",
    "output = results_ds['outputs'][idx_to_inspect]\n",
    "output_tokens = results_ds['output_tokens'][idx_to_inspect]\n",
    "gt_tokens = results_ds['ground_truth_tokens'][idx_to_inspect]\n",
    "gt = results_ds['ground_truths'][idx_to_inspect]\n",
    "\n",
    "# print(f\"\\nPROMPT (idx = {idx_to_inspect}):\\n{example_prompt}\\n\")\n",
    "print(f\"\\nMODEL OUTPUT:\\n{output}\\n\\nOUTPUT TOKENS:\\n{output_tokens}\")\n",
    "print(f\"\\nGROUND TRUTH:\\n{gt}\\n\\nGT TOKENS:\\n{gt_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will test the utility functions that compute metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred time ranges: ['(2010, 2012, 2013, 2014)', '(2010, 2011, 2012, 2013, 2014)', '(2010, 2011, 2012, 2013, 2014)', '(2010, 2011, 2012, 2013, 2014)']\n",
      "GT time ranges: ['(2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019)', '(2019, 2020)']\n",
      "Pred entities: ['Teachta Dála', 'Labour Party', 'Labour Party', 'Labour Party']\n",
      "GT entities: ['Socialist Party', 'RISE']\n",
      "\n",
      "EM: 0.0\n",
      "F1: 0.23636363636363636\n",
      "Recall: 0.30952380952380953\n",
      "Time BLEU: 0.7960980672538887\n",
      "Entity BERT: 0.5890607833862305\n"
     ]
    }
   ],
   "source": [
    "import metrics\n",
    "import utils\n",
    "import importlib\n",
    "import re\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(utils)\n",
    "\n",
    "\n",
    "gt_list = gt\n",
    "gt_tokens_list = gt_tokens\n",
    "pred_tokens_list = utils.remove_pad_tokens(output_tokens)\n",
    "pred_list = utils.extract_between_tags(output)\n",
    "pred_list = re.findall(r\"'(.*?)'\", pred_list)  # We convert the output string into list to facilitate metrics computation\n",
    "\n",
    "print(f\"Pred time ranges: {metrics.extract_time_ranges(pred_list)}\")\n",
    "print(f\"GT time ranges: {metrics.extract_time_ranges(gt_list)}\")\n",
    "print(f\"Pred entities: {metrics.extract_entities(pred_list)}\")\n",
    "print(f\"GT entities: {metrics.extract_entities(gt_list)}\")\n",
    "\n",
    "# ---------------------- Syntax-based metrics --------------------------\n",
    "em = metrics.compute_em(gt_list, pred_list)\n",
    "f1 = metrics.compute_f1(gt_tokens_list, pred_tokens_list)\n",
    "recall = metrics.compute_recall(gt_tokens_list, pred_tokens_list)\n",
    "time_bleu = metrics.compute_time_bleu(gt_list, pred_list, tokenizer)  # NOTE: tends to be relatively high, since the time range is already hinted at in the prompt\n",
    "# ---------------------- Semantics-based metrics --------------------------\n",
    "entity_bert = metrics.compute_entity_bert(gt_list, pred_list)   # Uses BERT tokenizer\n",
    "\n",
    "print(f\"\\nEM: {em}\")                              \n",
    "print(f\"F1: {f1}\")                      \n",
    "print(f\"Recall: {recall}\")                           \n",
    "print(f\"Time BLEU: {time_bleu}\")      \n",
    "print(f\"Entity BERT: {entity_bert}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
