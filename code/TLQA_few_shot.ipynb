{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot TLQA with FlanT5\n",
    "\n",
    "Below, we run generative models FlanT5-large and FlanT5-XL in a few-shot setting by selecting demonstration examples from training set of TLQA, which was derived from tempLLama.\n",
    "- `flan-t5-large`: 780M params, 1GB mem\n",
    "- `flan-t5-xl`: 3B params, 12 GB mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Obtaining dependency information for sentence-transformers from https://files.pythonhosted.org/packages/76/2c/bd95032aeb087b0706596af0a4518c4bfe0439a1bb149048ece18b617766/sentence_transformers-2.7.0-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (4.37.2)\n",
      "Requirement already satisfied: tqdm in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: numpy in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (0.23.0)\n",
      "Requirement already satisfied: Pillow in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.4.28)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nadinekuo/miniconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.37.2 optimum==1.12.0 --quiet\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running FlanT5-Large and FlanT5-XL (zero-shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/Users/nadinekuo/miniconda3/lib/python3.11/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Michael Jackson: The Greatest Hits</s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\", torch_dtype=torch.float16)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\")\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\")\n",
    "\n",
    "input_text = \"List all Michael Jackson albums between 2000 and 2009.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "# input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running FlanT5-XL on a CPU (zero-shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\")\n",
    "\n",
    "input_text = \"List all Michael Jackson albums between 1990 and 2009.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-Shot Setting\n",
    "\n",
    "To select few-shot examples, we select examples from the training set that are close to each test example by using KNN search in a continuous vector space using any embedding model from sentence-transformers.\n",
    "We reuse the KNN search from https://anonymous.4open.science/r/ICAT-47FC/code/2wikimultihopqa/get_chatgpt_skill_transfer_knn.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class KnnSearch:\n",
    "    def __init__(self, data=None, num_trees=None, emb_dim=None):\n",
    "        self.num_trees = num_trees\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "    def get_embeddings_for_data(self, data_ls):\n",
    "        model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "        embeddings = model.encode(data_ls)\n",
    "        return embeddings\n",
    "\n",
    "    def get_top_n_neighbours(self,sentence,data_emb,transfer_data,strategy_emb, str_qa,k):\n",
    "        sent_emb = self.get_embeddings_for_data(sentence)\n",
    "        #data_emb = self.get_embeddings_for_data(transfer_questions)\n",
    "        top_questions = []\n",
    "\n",
    "        print(\"new_emb\", sent_emb.shape, data_emb.shape)\n",
    "        text_sims = cosine_similarity(data_emb,[sent_emb]).tolist()\n",
    "        results_sims = zip(range(len(text_sims)), text_sims)\n",
    "        sorted_similarities = sorted(results_sims, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        #print(\"text_sims\",sorted_similarities[:2])\n",
    "        for idx, item in sorted_similarities[:k]:\n",
    "                #if item[0] > 0.45:\n",
    "                    top_questions.append(transfer_data[idx])\n",
    "   \n",
    "        text_sims = cosine_similarity(strategy_emb,[sent_emb]).tolist()\n",
    "        results_sims = zip(range(len(text_sims)), text_sims)\n",
    "        sorted_similarities = sorted(results_sims, key=lambda x: x[1], reverse=True)\n",
    "        #print(\"text_sims\",sorted_similarities[:2]) \n",
    "        for idx, item in sorted_similarities:\n",
    "                top_questions.append(str_qa[idx]) \n",
    "        return top_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
